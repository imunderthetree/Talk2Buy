{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caec7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyQt5 opencv-python numpy matplotlib torch torchvision trimesh open3d scikit-image scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26108736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, \n",
    "                             QLabel, QPushButton, QComboBox, QFileDialog, QMessageBox, \n",
    "                             QGroupBox, QProgressBar, QCheckBox, QSpinBox, QDoubleSpinBox,\n",
    "                             QTabWidget, QSizePolicy, QScrollArea, QLineEdit)\n",
    "from PyQt5.QtCore import Qt, QThread, pyqtSignal\n",
    "from PyQt5.QtGui import QPixmap, QImage, QIcon\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas\n",
    "from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar\n",
    "from matplotlib.figure import Figure\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from torchvision.transforms import functional as F\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import torch.hub\n",
    "from torchvision import transforms\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9159fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Original Functions --------------------\n",
    "\n",
    "def detect_objects_with_yolo(image):\n",
    "    \"\"\"Detect objects in the image using YOLO\"\"\"\n",
    "    print(\"Loading YOLO model...\")\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    \n",
    "    results = model(image)\n",
    "    detections = results.xyxy[0].cpu().numpy()\n",
    "    class_names = [model.names[int(cls)] for cls in detections[:, 5]]\n",
    "    \n",
    "    return detections, class_names\n",
    "\n",
    "def yolo_based_roi_selection(image, min_confidence=0.4):\n",
    "    \"\"\"Select region of interest based on YOLO object detection\"\"\"\n",
    "    detections, class_names = detect_objects_with_yolo(image)\n",
    "    \n",
    "    if len(detections) > 0:\n",
    "        valid_detections = detections[detections[:, 4] >= min_confidence]\n",
    "        \n",
    "        if len(valid_detections) > 0:\n",
    "            best_idx = np.argmax([d[4] for d in valid_detections])\n",
    "            selected_det = valid_detections[best_idx]\n",
    "            class_name = class_names[best_idx]\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, selected_det[:4])\n",
    "            padding_percent = 0.1\n",
    "            pad_x = int((x2 - x1) * padding_percent)\n",
    "            pad_y = int((y2 - y1) * padding_percent)\n",
    "            \n",
    "            h, w = image.shape[:2]\n",
    "            x1 = max(0, x1 - pad_x)\n",
    "            y1 = max(0, y1 - pad_y)\n",
    "            x2 = min(w, x2 + pad_x)\n",
    "            y2 = min(h, y2 + pad_y)\n",
    "            \n",
    "            return (x1, y1, x2, y2), class_name\n",
    "    \n",
    "    return enhanced_auto_select_roi(image), \"unknown\"\n",
    "\n",
    "def auto_select_depth_model(image):\n",
    "    \"\"\"Select best depth estimation model based on image characteristics\"\"\"\n",
    "    img_size = image.shape[0] * image.shape[1]\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    \n",
    "    if img_size > 1_000_000 and laplacian_var > 100:\n",
    "        model_type = \"DPT_Large\"\n",
    "    elif laplacian_var > 70:\n",
    "        model_type = \"DPT_Hybrid\"\n",
    "    else:\n",
    "        model_type = \"MiDaS_small\"\n",
    "    \n",
    "    midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "    midas.to('cuda' if torch.cuda.is_available() else 'cpu').eval()\n",
    "    \n",
    "    if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "        transform = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\").dpt_transform\n",
    "    else:\n",
    "        transform = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\").small_transform\n",
    "        \n",
    "    return midas, transform, model_type\n",
    "\n",
    "def enhanced_auto_select_roi(image):\n",
    "    \"\"\"Automatic selection of ROI using multiple techniques\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh_adaptive = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                         cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    _, thresh_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    combined_mask = cv2.bitwise_or(thresh_adaptive, thresh_otsu)\n",
    "    \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_eroded = cv2.erode(cv2.dilate(combined_mask, kernel, iterations=1), kernel, iterations=1)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask_eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > max(500, (width * height * 0.01))]\n",
    "    \n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        padding_percent = 0.15\n",
    "        padding_x = int(w * padding_percent)\n",
    "        padding_y = int(h * padding_percent)\n",
    "        \n",
    "        x1 = max(0, x - padding_x)\n",
    "        y1 = max(0, y - padding_y)\n",
    "        x2 = min(width, x + w + padding_x)\n",
    "        y2 = min(height, y + h + padding_y)\n",
    "        \n",
    "        if (x2 - x1) < 50 or (y2 - y1) < 50:\n",
    "            center_x, center_y = width // 2, height // 2\n",
    "            min_dim = max(100, min(width, height) // 4)\n",
    "            x1 = max(0, center_x - min_dim // 2)\n",
    "            y1 = max(0, center_y - min_dim // 2)\n",
    "            x2 = min(width, center_x + min_dim // 2)\n",
    "            y2 = min(height, center_y + min_dim // 2)\n",
    "        \n",
    "        return (x1, y1, x2, y2)\n",
    "    \n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    size = min(width, height) // 2\n",
    "    return max(0, center_x - size), max(0, center_y - size), min(width, center_x + size), min(height, center_y + size)\n",
    "\n",
    "def get_object_specific_params(class_name):\n",
    "    \"\"\"Get parameters for different object types\"\"\"\n",
    "    object_params = {\n",
    "        'person': {'scale_z': 0.6, 'smoothing': 5, 'mesh_detail': 9, 'outlier_removal': 2.0},\n",
    "        'car': {'scale_z': 0.5, 'smoothing': 3, 'mesh_detail': 9, 'outlier_removal': 1.8},\n",
    "        'bottle': {'scale_z': 1.0, 'smoothing': 7, 'mesh_detail': 8, 'outlier_removal': 2.2},\n",
    "        'default': {'scale_z': 0.5, 'smoothing': 5, 'mesh_detail': 8, 'outlier_removal': 2.0}\n",
    "    }\n",
    "    return object_params.get(class_name.lower(), object_params['default'])\n",
    "\n",
    "def get_enhanced_depth(image, midas, transform):\n",
    "    \"\"\"Get depth with additional post-processing\"\"\"\n",
    "    input_batch = transform(image).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "    \n",
    "    depth = prediction.squeeze().cpu().numpy()\n",
    "    depth_normalized = cv2.normalize(depth, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    depth_normalized = (depth_normalized * 255).astype(np.uint8)\n",
    "    depth_filtered = cv2.bilateralFilter(depth_normalized, 9, 75, 75)\n",
    "    depth_filtered = depth_filtered.astype(np.float32) / 255\n",
    "    depth_filtered = depth_filtered * (depth.max() - depth.min()) + depth.min()\n",
    "    \n",
    "    percentile_low, percentile_high = np.percentile(depth_filtered, [2, 98])\n",
    "    depth_filtered = np.clip(depth_filtered, percentile_low, percentile_high)\n",
    "    \n",
    "    return depth_filtered\n",
    "\n",
    "def extract_3d_from_roi(depth_map, roi, image, object_params):\n",
    "    \"\"\"Extract 3D points with object-specific parameters\"\"\"\n",
    "    x1, y1, x2, y2 = roi\n",
    "    roi_depth = depth_map[y1:y2, x1:x2]\n",
    "    roi_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "    roi_depth = cv2.GaussianBlur(roi_depth, (3, 3), 0)\n",
    "    h, w = roi_depth.shape\n",
    "    yy, xx = np.mgrid[0:h, 0:w]\n",
    "    \n",
    "    depth_min = np.percentile(roi_depth, 5)\n",
    "    depth_max = np.percentile(roi_depth, 95)\n",
    "    depth_scaled = np.clip(roi_depth, depth_min, depth_max)\n",
    "    depth_scaled = (depth_scaled - depth_min) / (depth_max - depth_min)\n",
    "    \n",
    "    mask = ~np.isnan(depth_scaled)\n",
    "    xx_valid = xx[mask]\n",
    "    yy_valid = yy[mask]\n",
    "    depth_valid = depth_scaled[mask]\n",
    "    \n",
    "    num_points = np.sum(mask)\n",
    "    points = np.zeros((num_points, 6))\n",
    "    \n",
    "    scale_x = 1.0\n",
    "    scale_y = h / w if h > w else 1.0\n",
    "    scale_z = object_params['scale_z']\n",
    "    \n",
    "    points[:, 0] = xx_valid * scale_x\n",
    "    points[:, 1] = yy_valid * scale_y\n",
    "    points[:, 2] = depth_valid * scale_z\n",
    "    \n",
    "    for i, (x, y) in enumerate(zip(xx_valid, yy_valid)):\n",
    "        points[i, 3:6] = roi_image[y, x] / 255.0\n",
    "    \n",
    "    points[:, 0] = (points[:, 0] / w - 0.5) * 2\n",
    "    points[:, 1] = (points[:, 1] / h - 0.5) * 2\n",
    "    \n",
    "    return points\n",
    "\n",
    "def generate_enhanced_3d_model(points, method=\"mesh\", object_params=None):\n",
    "    \"\"\"Generate 3D model with object-specific parameters\"\"\"\n",
    "    if object_params is None:\n",
    "        object_params = get_object_specific_params(\"default\")\n",
    "        \n",
    "    if method == \"pointcloud\":\n",
    "        return points\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(points[:, 3:6])\n",
    "    \n",
    "    if len(pcd.points) > 50000:\n",
    "        pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "    \n",
    "    pcd, _ = pcd.remove_statistical_outlier(\n",
    "        nb_neighbors=20, \n",
    "        std_ratio=object_params['outlier_removal']\n",
    "    )\n",
    "    \n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=15)\n",
    "    \n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "        pcd, \n",
    "        depth=object_params['mesh_detail'],\n",
    "        width=0, \n",
    "        scale=1.1, \n",
    "        linear_fit=False\n",
    "    )\n",
    "    \n",
    "    density_threshold = np.quantile(densities, 0.1)\n",
    "    vertices_to_remove = densities < density_threshold\n",
    "    mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "    \n",
    "    if len(mesh.triangles) > 100000:\n",
    "        mesh = mesh.simplify_quadric_decimation(target_number_of_triangles=100000)\n",
    "    \n",
    "    mesh = mesh.filter_smooth_taubin(number_of_iterations=object_params['smoothing'])\n",
    "    \n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    vertex_colors = np.zeros((len(vertices), 3))\n",
    "    \n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    for i, vertex in enumerate(vertices):\n",
    "        _, idx, _ = pcd_tree.search_knn_vector_3d(vertex, 1)\n",
    "        if idx:\n",
    "            vertex_colors[i] = np.asarray(pcd.colors)[idx[0]]\n",
    "    \n",
    "    mesh.vertex_colors = o3d.utility.Vector3dVector(vertex_colors)\n",
    "    \n",
    "    tri_mesh = trimesh.Trimesh(vertices=vertices,\n",
    "                              faces=np.asarray(mesh.triangles),\n",
    "                              vertex_colors=vertex_colors)\n",
    "    \n",
    "    tri_mesh.remove_duplicate_faces()\n",
    "    tri_mesh.remove_degenerate_faces()\n",
    "    tri_mesh.remove_unreferenced_vertices()\n",
    "    \n",
    "    return tri_mesh\n",
    "\n",
    "def save_3d_model(model, filename, method=\"mesh\"):\n",
    "    \"\"\"Save 3D model in appropriate format\"\"\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    if method == \"pointcloud\":\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(model[:, :3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(model[:, 3:6])\n",
    "        o3d.io.write_point_cloud(filename, pcd)\n",
    "    elif method == \"mesh\":\n",
    "        ext = os.path.splitext(filename)[1].lower()\n",
    "        if ext == '.ply':\n",
    "            model.export(filename, file_type='ply')\n",
    "        elif ext == '.obj':\n",
    "            model.export(filename, file_type='obj')\n",
    "        elif ext == '.stl':\n",
    "            model.export(filename, file_type='stl')\n",
    "        elif ext == '.glb':\n",
    "            model.export(filename, file_type='glb')\n",
    "        else:\n",
    "            filename = os.path.splitext(filename)[0] + '.ply'\n",
    "            model.export(filename, file_type='ply')\n",
    "\n",
    "# -------------------- Worker Thread --------------------\n",
    "\n",
    "class WorkerThread(QThread):\n",
    "    progress_signal = pyqtSignal(int, str)\n",
    "    finished_signal = pyqtSignal(object, str, str, np.ndarray, np.ndarray, tuple)\n",
    "    error_signal = pyqtSignal(str)\n",
    "    preview_signal = pyqtSignal(np.ndarray, np.ndarray, tuple)\n",
    "\n",
    "    def __init__(self, image_path, roi_method, output_method, output_dir, params):\n",
    "        super().__init__()\n",
    "        self.image_path = image_path\n",
    "        self.roi_method = roi_method\n",
    "        self.output_method = output_method\n",
    "        self.output_dir = output_dir\n",
    "        self.params = params\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            # Load image\n",
    "            self.progress_signal.emit(5, \"Loading image...\")\n",
    "            image = cv2.cvtColor(cv2.imread(self.image_path), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Select ROI\n",
    "            self.progress_signal.emit(15, \"Selecting region of interest...\")\n",
    "            if self.roi_method == \"auto\":\n",
    "                roi, class_name = yolo_based_roi_selection(image)\n",
    "            elif self.roi_method == \"manual\":\n",
    "                roi = enhanced_auto_select_roi(image)\n",
    "                class_name = \"unknown\"\n",
    "            else:\n",
    "                roi = enhanced_auto_select_roi(image)\n",
    "                class_name = \"unknown\"\n",
    "            \n",
    "            # Get parameters\n",
    "            self.progress_signal.emit(25, \"Configuring parameters...\")\n",
    "            object_params = {\n",
    "                'scale_z': self.params['scale_z'],\n",
    "                'smoothing': self.params['smoothing'],\n",
    "                'mesh_detail': self.params['detail'],\n",
    "                'outlier_removal': self.params['outlier']\n",
    "            }\n",
    "            \n",
    "            # Initialize model\n",
    "            self.progress_signal.emit(35, \"Initializing depth model...\")\n",
    "            midas, transform, model_type = auto_select_depth_model(image)\n",
    "            \n",
    "            # Generate depth map\n",
    "            self.progress_signal.emit(50, \"Generating depth map...\")\n",
    "            depth = get_enhanced_depth(image, midas, transform)\n",
    "            \n",
    "            # Extract 3D points\n",
    "            self.progress_signal.emit(65, \"Extracting 3D points...\")\n",
    "            points_3d = extract_3d_from_roi(depth, roi, image, object_params)\n",
    "            \n",
    "            # Generate 3D model\n",
    "            self.progress_signal.emit(80, \"Generating 3D model...\")\n",
    "            model_3d = generate_enhanced_3d_model(points_3d, self.output_method, object_params)\n",
    "            \n",
    "            # Emit preview data\n",
    "            self.preview_signal.emit(image, depth, roi)\n",
    "            \n",
    "            # Save model\n",
    "            self.progress_signal.emit(90, \"Saving results...\")\n",
    "            base_name = os.path.splitext(os.path.basename(self.image_path))[0]\n",
    "            output_file = os.path.join(self.output_dir, f\"{base_name}_{self.output_method}_{class_name}\")\n",
    "            \n",
    "            if self.output_method == \"pointcloud\":\n",
    "                output_file += \".ply\"\n",
    "            else:\n",
    "                output_file += \".obj\"\n",
    "            \n",
    "            save_3d_model(model_3d, output_file, method=self.output_method)\n",
    "            \n",
    "            self.finished_signal.emit(model_3d, class_name, model_type, image, depth, roi)\n",
    "            self.progress_signal.emit(100, \"Finished!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.error_signal.emit(str(e))\n",
    "\n",
    "# -------------------- Main Window --------------------\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"3D Model Generator\")\n",
    "        self.setGeometry(100, 100, 1200, 800)\n",
    "        \n",
    "        # Central widget and layout\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        main_layout = QHBoxLayout(central_widget)\n",
    "        \n",
    "        # Left panel (controls)\n",
    "        left_panel = QWidget()\n",
    "        left_panel.setMaximumWidth(300)\n",
    "        left_layout = QVBoxLayout(left_panel)\n",
    "        \n",
    "        # Right panel (display)\n",
    "        right_panel = QTabWidget()\n",
    "        right_panel.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n",
    "        \n",
    "        # Add panels to main layout\n",
    "        main_layout.addWidget(left_panel)\n",
    "        main_layout.addWidget(right_panel)\n",
    "        \n",
    "        # -------------------- Left Panel Controls --------------------\n",
    "        \n",
    "        # Input group\n",
    "        input_group = QGroupBox(\"Input Settings\")\n",
    "        input_layout = QVBoxLayout()\n",
    "        \n",
    "        self.image_path_edit = QLineEdit()\n",
    "        self.image_path_edit.setPlaceholderText(\"Select image file...\")\n",
    "        browse_btn = QPushButton(\"Browse...\")\n",
    "        browse_btn.clicked.connect(self.browse_image)\n",
    "        \n",
    "        input_layout.addWidget(QLabel(\"Image File:\"))\n",
    "        input_layout.addWidget(self.image_path_edit)\n",
    "        input_layout.addWidget(browse_btn)\n",
    "        input_group.setLayout(input_layout)\n",
    "        \n",
    "        # ROI group\n",
    "        roi_group = QGroupBox(\"ROI Selection\")\n",
    "        roi_layout = QVBoxLayout()\n",
    "        \n",
    "        self.roi_method_combo = QComboBox()\n",
    "        self.roi_method_combo.addItems([\"Auto (YOLO)\", \"Auto (Traditional)\", \"Manual\"])\n",
    "        \n",
    "        roi_layout.addWidget(QLabel(\"Selection Method:\"))\n",
    "        roi_layout.addWidget(self.roi_method_combo)\n",
    "        roi_group.setLayout(roi_layout)\n",
    "        \n",
    "        # Output group\n",
    "        output_group = QGroupBox(\"Output Settings\")\n",
    "        output_layout = QVBoxLayout()\n",
    "        \n",
    "        self.output_method_combo = QComboBox()\n",
    "        self.output_method_combo.addItems([\"Mesh\", \"Point Cloud\"])\n",
    "        \n",
    "        self.output_dir_edit = QLineEdit()\n",
    "        self.output_dir_edit.setPlaceholderText(\"Select output directory...\")\n",
    "        output_browse_btn = QPushButton(\"Browse...\")\n",
    "        output_browse_btn.clicked.connect(self.browse_output_dir)\n",
    "        \n",
    "        output_layout.addWidget(QLabel(\"Output Type:\"))\n",
    "        output_layout.addWidget(self.output_method_combo)\n",
    "        output_layout.addWidget(QLabel(\"Output Directory:\"))\n",
    "        output_layout.addWidget(self.output_dir_edit)\n",
    "        output_layout.addWidget(output_browse_btn)\n",
    "        output_group.setLayout(output_layout)\n",
    "        \n",
    "        # Parameters group\n",
    "        params_group = QGroupBox(\"3D Generation Parameters\")\n",
    "        params_layout = QVBoxLayout()\n",
    "        \n",
    "        self.scale_z_spin = QDoubleSpinBox()\n",
    "        self.scale_z_spin.setRange(0.1, 2.0)\n",
    "        self.scale_z_spin.setValue(0.5)\n",
    "        self.scale_z_spin.setSingleStep(0.1)\n",
    "        \n",
    "        self.smoothing_spin = QSpinBox()\n",
    "        self.smoothing_spin.setRange(1, 10)\n",
    "        self.smoothing_spin.setValue(5)\n",
    "        \n",
    "        self.detail_spin = QSpinBox()\n",
    "        self.detail_spin.setRange(5, 12)\n",
    "        self.detail_spin.setValue(8)\n",
    "        \n",
    "        self.outlier_spin = QDoubleSpinBox()\n",
    "        self.outlier_spin.setRange(1.0, 3.0)\n",
    "        self.outlier_spin.setValue(2.0)\n",
    "        self.outlier_spin.setSingleStep(0.1)\n",
    "        \n",
    "        params_layout.addWidget(QLabel(\"Depth Scale (Z):\"))\n",
    "        params_layout.addWidget(self.scale_z_spin)\n",
    "        params_layout.addWidget(QLabel(\"Smoothing Iterations:\"))\n",
    "        params_layout.addWidget(self.smoothing_spin)\n",
    "        params_layout.addWidget(QLabel(\"Mesh Detail Level:\"))\n",
    "        params_layout.addWidget(self.detail_spin)\n",
    "        params_layout.addWidget(QLabel(\"Outlier Removal:\"))\n",
    "        params_layout.addWidget(self.outlier_spin)\n",
    "        params_group.setLayout(params_layout)\n",
    "        \n",
    "        # Process controls\n",
    "        process_group = QGroupBox(\"Processing\")\n",
    "        process_layout = QVBoxLayout()\n",
    "        \n",
    "        self.progress_bar = QProgressBar()\n",
    "        self.progress_label = QLabel(\"Ready\")\n",
    "        self.process_btn = QPushButton(\"Generate 3D Model\")\n",
    "        self.process_btn.clicked.connect(self.start_processing)\n",
    "        self.cancel_btn = QPushButton(\"Cancel\")\n",
    "        self.cancel_btn.setEnabled(False)\n",
    "        \n",
    "        process_layout.addWidget(self.progress_bar)\n",
    "        process_layout.addWidget(self.progress_label)\n",
    "        process_layout.addWidget(self.process_btn)\n",
    "        process_layout.addWidget(self.cancel_btn)\n",
    "        process_group.setLayout(process_layout)\n",
    "        \n",
    "        # Add all groups to left panel\n",
    "        left_layout.addWidget(input_group)\n",
    "        left_layout.addWidget(roi_group)\n",
    "        left_layout.addWidget(output_group)\n",
    "        left_layout.addWidget(params_group)\n",
    "        left_layout.addWidget(process_group)\n",
    "        left_layout.addStretch()\n",
    "        \n",
    "        # -------------------- Right Panel Tabs --------------------\n",
    "        \n",
    "        # Input image tab\n",
    "        self.input_tab = QWidget()\n",
    "        self.input_layout = QVBoxLayout(self.input_tab)\n",
    "        \n",
    "        self.input_figure = Figure()\n",
    "        self.input_canvas = FigureCanvas(self.input_figure)\n",
    "        self.input_toolbar = NavigationToolbar(self.input_canvas, self)\n",
    "        \n",
    "        self.input_layout.addWidget(self.input_toolbar)\n",
    "        self.input_layout.addWidget(self.input_canvas)\n",
    "        \n",
    "        # Depth map tab\n",
    "        self.depth_tab = QWidget()\n",
    "        self.depth_layout = QVBoxLayout(self.depth_tab)\n",
    "        \n",
    "        self.depth_figure = Figure()\n",
    "        self.depth_canvas = FigureCanvas(self.depth_figure)\n",
    "        self.depth_toolbar = NavigationToolbar(self.depth_canvas, self)\n",
    "        \n",
    "        self.depth_layout.addWidget(self.depth_toolbar)\n",
    "        self.depth_layout.addWidget(self.depth_canvas)\n",
    "        \n",
    "        # Results tab\n",
    "        self.results_tab = QWidget()\n",
    "        self.results_layout = QVBoxLayout(self.results_tab)\n",
    "        \n",
    "        self.results_label = QLabel(\"Results will be shown here after processing\")\n",
    "        self.results_label.setAlignment(Qt.AlignCenter)\n",
    "        self.results_layout.addWidget(self.results_label)\n",
    "        \n",
    "        # Add tabs to right panel\n",
    "        right_panel.addTab(self.input_tab, \"Input Image\")\n",
    "        right_panel.addTab(self.depth_tab, \"Depth Map\")\n",
    "        right_panel.addTab(self.results_tab, \"Results\")\n",
    "        \n",
    "        # Worker thread\n",
    "        self.worker_thread = None\n",
    "        \n",
    "        # Initialize CUDA status\n",
    "        self.update_cuda_status()\n",
    "        \n",
    "    def update_cuda_status(self):\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        status = \"CUDA: \" + (\"Available\" if cuda_available else \"Not Available\")\n",
    "        self.statusBar().showMessage(status)\n",
    "        \n",
    "    def browse_image(self):\n",
    "        file_path, _ = QFileDialog.getOpenFileName(\n",
    "            self, \"Select Image\", \"\", \n",
    "            \"Image Files (*.png *.jpg *.jpeg *.bmp)\"\n",
    "        )\n",
    "        if file_path:\n",
    "            self.image_path_edit.setText(file_path)\n",
    "            self.display_input_image(file_path)\n",
    "            \n",
    "    def browse_output_dir(self):\n",
    "        dir_path = QFileDialog.getExistingDirectory(self, \"Select Output Directory\")\n",
    "        if dir_path:\n",
    "            self.output_dir_edit.setText(dir_path)\n",
    "            \n",
    "    def display_input_image(self, image_path):\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        self.input_figure.clear()\n",
    "        ax = self.input_figure.add_subplot(111)\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        self.input_canvas.draw()\n",
    "        \n",
    "    def start_processing(self):\n",
    "        if not self.image_path_edit.text():\n",
    "            QMessageBox.warning(self, \"Error\", \"Please select an image file first!\")\n",
    "            return\n",
    "            \n",
    "        if not self.output_dir_edit.text():\n",
    "            QMessageBox.warning(self, \"Error\", \"Please select an output directory!\")\n",
    "            return\n",
    "            \n",
    "        # Get parameters from UI\n",
    "        roi_method = [\"auto\", \"auto\", \"manual\"][self.roi_method_combo.currentIndex()]\n",
    "        output_method = [\"mesh\", \"pointcloud\"][self.output_method_combo.currentIndex()]\n",
    "        \n",
    "        params = {\n",
    "            'scale_z': self.scale_z_spin.value(),\n",
    "            'smoothing': self.smoothing_spin.value(),\n",
    "            'detail': self.detail_spin.value(),\n",
    "            'outlier': self.outlier_spin.value()\n",
    "        }\n",
    "        \n",
    "        # Create and start worker thread\n",
    "        self.worker_thread = WorkerThread(\n",
    "            self.image_path_edit.text(),\n",
    "            roi_method,\n",
    "            output_method,\n",
    "            self.output_dir_edit.text(),\n",
    "            params\n",
    "        )\n",
    "        \n",
    "        # Connect signals\n",
    "        self.worker_thread.progress_signal.connect(self.update_progress)\n",
    "        self.worker_thread.finished_signal.connect(self.processing_finished)\n",
    "        self.worker_thread.error_signal.connect(self.processing_error)\n",
    "        self.worker_thread.preview_signal.connect(self.update_previews)\n",
    "        \n",
    "        # Update UI\n",
    "        self.process_btn.setEnabled(False)\n",
    "        self.cancel_btn.setEnabled(True)\n",
    "        self.progress_bar.setValue(0)\n",
    "        self.progress_label.setText(\"Processing...\")\n",
    "        \n",
    "        # Start thread\n",
    "        self.worker_thread.start()\n",
    "        \n",
    "    def update_progress(self, value, message):\n",
    "        self.progress_bar.setValue(value)\n",
    "        self.progress_label.setText(message)\n",
    "        \n",
    "    def update_previews(self, image, depth, roi):\n",
    "        # Update input image with ROI\n",
    "        self.input_figure.clear()\n",
    "        ax = self.input_figure.add_subplot(111)\n",
    "        ax.imshow(image)\n",
    "        x1, y1, x2, y2 = roi\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.axis('off')\n",
    "        self.input_canvas.draw()\n",
    "        \n",
    "        # Update depth map\n",
    "        self.depth_figure.clear()\n",
    "        ax = self.depth_figure.add_subplot(111)\n",
    "        ax.imshow(depth, cmap='plasma')\n",
    "        ax.axis('off')\n",
    "        self.depth_canvas.draw()\n",
    "        \n",
    "    def processing_finished(self, model_3d, class_name, model_type, image, depth, roi):\n",
    "        self.process_btn.setEnabled(True)\n",
    "        self.cancel_btn.setEnabled(False)\n",
    "        self.progress_label.setText(\"Finished!\")\n",
    "        \n",
    "        # Update results tab\n",
    "        self.results_label.setText(\n",
    "            f\"3D Model Generation Complete!\\n\\n\"\n",
    "            f\"Object Type: {class_name}\\n\"\n",
    "            f\"Depth Model: {model_type}\\n\"\n",
    "            f\"ROI: {roi}\\n\\n\"\n",
    "            f\"Model saved to output directory.\"\n",
    "        )\n",
    "        \n",
    "        QMessageBox.information(self, \"Success\", \"3D model generation completed successfully!\")\n",
    "        \n",
    "    def processing_error(self, error_message):\n",
    "        self.process_btn.setEnabled(True)\n",
    "        self.cancel_btn.setEnabled(False)\n",
    "        self.progress_label.setText(\"Error occurred\")\n",
    "        \n",
    "        QMessageBox.critical(self, \"Error\", f\"An error occurred:\\n{error_message}\")\n",
    "        \n",
    "    def closeEvent(self, event):\n",
    "        if self.worker_thread and self.worker_thread.isRunning():\n",
    "            self.worker_thread.terminate()\n",
    "            self.worker_thread.wait()\n",
    "        event.accept()\n",
    "\n",
    "# -------------------- Application --------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    \n",
    "    # Set application style\n",
    "    app.setStyle('Fusion')\n",
    "    \n",
    "    # Create and show main window\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    \n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
